2019-02-20 12:36:47,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = monkeydlyffy
STARTUP_MSG:   host = Monkeys-MBP/192.168.1.134
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/monkeydlyffy/hadoop-2.8.1/etc/hadoop:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 11.0.2
************************************************************/
2019-02-20 12:36:47,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 12:36:47,371 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:36:47,433 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:36:47,447 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:36:47,459 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:36:47,486 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-02-20 12:36:47,508 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:36:47,770 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 12:36:47,841 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 12:36:47,842 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-02-20 12:36:47,848 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-02-20 12:36:47,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is monkeys-mbp
2019-02-20 12:36:47,852 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-02-20 12:36:47,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-02-20 12:36:47,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2019-02-20 12:36:47,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-02-20 12:36:47,961 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-20 12:36:47,966 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 12:36:47,970 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-02-20 12:36:47,975 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 12:36:47,976 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-02-20 12:36:47,976 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 12:36:47,976 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 12:36:47,988 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49363
2019-02-20 12:36:47,988 INFO org.mortbay.log: jetty-6.1.26
2019-02-20 12:36:48,036 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49363
2019-02-20 12:36:48,118 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-02-20 12:36:48,177 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-02-20 12:36:48,180 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 12:36:48,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = monkeydlyffy
2019-02-20 12:36:48,205 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-02-20 12:36:48,240 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 12:36:48,251 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-02-20 12:36:48,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-02-20 12:36:48,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-02-20 12:36:48,322 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2019-02-20 12:36:48,427 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2019-02-20 12:36:48,429 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2019-02-20 12:36:48,430 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2019-02-20 12:36:48,430 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2019-02-20 12:36:48,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2019-02-20 12:36:48,431 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2019-02-20 12:36:48,433 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-02-20 12:36:48,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at Monkeys-MBP/192.168.1.134
************************************************************/
2019-02-20 12:53:45,680 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = monkeydlyffy
STARTUP_MSG:   host = Monkeys-MBP/192.168.1.134
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/monkeydlyffy/hadoop-2.8.1/etc/hadoop:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 11.0.2
************************************************************/
2019-02-20 12:53:45,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 12:53:45,856 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:53:45,920 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:53:45,932 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:53:45,944 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:53:45,973 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-02-20 12:53:45,994 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 12:53:46,221 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 12:53:46,290 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 12:53:46,290 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-02-20 12:53:46,295 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-02-20 12:53:46,295 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is monkeys-mbp
2019-02-20 12:53:46,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-02-20 12:53:46,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-02-20 12:53:46,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2019-02-20 12:53:46,316 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-02-20 12:53:46,371 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-20 12:53:46,376 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 12:53:46,381 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-02-20 12:53:46,385 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 12:53:46,386 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-02-20 12:53:46,386 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 12:53:46,386 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 12:53:46,396 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49509
2019-02-20 12:53:46,396 INFO org.mortbay.log: jetty-6.1.26
2019-02-20 12:53:46,450 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49509
2019-02-20 12:53:46,515 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-02-20 12:53:46,558 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-02-20 12:53:46,561 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 12:53:46,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = monkeydlyffy
2019-02-20 12:53:46,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-02-20 12:53:46,619 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 12:53:46,627 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-02-20 12:53:46,664 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-02-20 12:53:46,672 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-02-20 12:53:46,683 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2019-02-20 12:53:46,789 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2019-02-20 12:53:46,790 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2019-02-20 12:53:46,790 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2019-02-20 12:53:46,791 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2019-02-20 12:53:46,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2019-02-20 12:53:46,791 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2019-02-20 12:53:46,794 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-02-20 12:53:46,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at Monkeys-MBP/192.168.1.134
************************************************************/
2019-02-20 13:25:00,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = monkeydlyffy
STARTUP_MSG:   host = Monkeys-MBP/192.168.1.134
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/monkeydlyffy/hadoop-2.8.1/etc/hadoop:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 11.0.2
************************************************************/
2019-02-20 13:25:00,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 13:25:01,134 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:25:01,196 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:25:01,208 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:25:01,220 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:25:01,247 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-02-20 13:25:01,269 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:25:01,491 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 13:25:01,562 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 13:25:01,563 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-02-20 13:25:01,568 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-02-20 13:25:01,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is monkeys-mbp
2019-02-20 13:25:01,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-02-20 13:25:01,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-02-20 13:25:01,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2019-02-20 13:25:01,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-02-20 13:25:01,647 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-20 13:25:01,651 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 13:25:01,656 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-02-20 13:25:01,660 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 13:25:01,661 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-02-20 13:25:01,661 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 13:25:01,661 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 13:25:01,671 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49965
2019-02-20 13:25:01,671 INFO org.mortbay.log: jetty-6.1.26
2019-02-20 13:25:01,719 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49965
2019-02-20 13:25:01,791 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-02-20 13:25:01,841 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-02-20 13:25:01,845 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 13:25:01,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = monkeydlyffy
2019-02-20 13:25:01,875 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-02-20 13:25:01,909 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 13:25:01,918 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-02-20 13:25:01,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-02-20 13:25:01,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-02-20 13:25:01,984 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2019-02-20 13:25:02,085 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2019-02-20 13:25:02,085 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2019-02-20 13:25:02,085 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2019-02-20 13:25:02,086 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2019-02-20 13:25:02,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2019-02-20 13:25:02,086 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2019-02-20 13:25:02,087 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-02-20 13:25:02,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at Monkeys-MBP/192.168.1.134
************************************************************/
2019-02-20 13:53:16,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = monkeydlyffy
STARTUP_MSG:   host = Monkeys-MBP/192.168.1.134
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/monkeydlyffy/hadoop-2.8.1/etc/hadoop:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 11.0.2
************************************************************/
2019-02-20 13:53:16,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-20 13:53:16,879 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:53:16,941 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:53:16,955 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:53:16,966 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:53:16,995 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-02-20 13:53:17,017 WARN org.apache.hadoop.conf.Configuration: hdfs-default.xml:an attempt to override final parameter: dfs.namenode.name.dir;  Ignoring.
2019-02-20 13:53:17,270 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-20 13:53:17,347 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-20 13:53:17,347 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-02-20 13:53:17,353 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-02-20 13:53:17,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is monkeys-mbp
2019-02-20 13:53:17,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-02-20 13:53:17,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-02-20 13:53:17,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2019-02-20 13:53:17,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-02-20 13:53:17,430 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-20 13:53:17,435 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-20 13:53:17,439 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-02-20 13:53:17,443 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-20 13:53:17,444 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-02-20 13:53:17,445 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-20 13:53:17,445 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-20 13:53:17,455 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50183
2019-02-20 13:53:17,455 INFO org.mortbay.log: jetty-6.1.26
2019-02-20 13:53:17,507 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:50183
2019-02-20 13:53:17,575 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-02-20 13:53:17,626 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-02-20 13:53:17,630 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-20 13:53:17,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = monkeydlyffy
2019-02-20 13:53:17,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-02-20 13:53:17,690 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-20 13:53:17,698 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-02-20 13:53:17,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-02-20 13:53:17,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-02-20 13:53:17,762 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2019-02-20 13:53:17,868 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2019-02-20 13:53:17,868 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2019-02-20 13:53:17,869 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2019-02-20 13:53:17,869 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2019-02-20 13:53:17,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2019-02-20 13:53:17,869 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddressesForCluster(DFSUtil.java:579)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:152)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2601)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2489)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:2536)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2721)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2745)
2019-02-20 13:53:17,871 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2019-02-20 13:53:17,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at Monkeys-MBP/192.168.1.134
************************************************************/
2019-02-21 10:58:13,549 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = monkeydlyffy
STARTUP_MSG:   host = Monkeys-MBP/192.168.1.134
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/monkeydlyffy/hadoop-2.8.1/etc/hadoop:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 11.0.2
************************************************************/
2019-02-21 10:58:13,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-21 10:58:13,843 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-02-21 10:58:14,092 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-21 10:58:14,163 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-21 10:58:14,163 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-02-21 10:58:14,169 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-02-21 10:58:14,169 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is monkeys-mbp
2019-02-21 10:58:14,173 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-02-21 10:58:14,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-02-21 10:58:14,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2019-02-21 10:58:14,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-02-21 10:58:14,252 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-21 10:58:14,257 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-21 10:58:14,261 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-02-21 10:58:14,265 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-21 10:58:14,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-02-21 10:58:14,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-21 10:58:14,266 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-21 10:58:14,277 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 49733
2019-02-21 10:58:14,277 INFO org.mortbay.log: jetty-6.1.26
2019-02-21 10:58:14,324 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:49733
2019-02-21 10:58:14,408 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-02-21 10:58:14,470 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-02-21 10:58:14,474 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-21 10:58:14,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = monkeydlyffy
2019-02-21 10:58:14,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-02-21 10:58:14,522 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-21 10:58:14,530 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-02-21 10:58:14,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-02-21 10:58:14,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-02-21 10:58:14,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-02-21 10:58:14,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-02-21 10:58:14,599 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-21 10:58:14,599 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-02-21 10:58:14,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-02-21 10:58:14,776 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-02-21 10:58:14,782 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /Users/monkeydlyffy/hadoop-2.8.1/data/in_use.lock acquired by nodename 972@Monkeys-MBP
2019-02-21 10:58:14,822 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-2058785796-10.151.1.170-1550698384810
2019-02-21 10:58:14,822 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810
2019-02-21 10:58:14,823 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2023373140;bpid=BP-2058785796-10.151.1.170-1550698384810;lv=-57;nsInfo=lv=-63;cid=CID-f007f2a9-35ba-4354-9294-82cd50046184;nsid=2023373140;c=1550698384810;bpid=BP-2058785796-10.151.1.170-1550698384810;dnuuid=38fba316-5bd4-419c-b295-da4bfcdd1ab5
2019-02-21 10:58:14,858 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-0d9bb1b0-7e9e-4c26-bcc7-ac7f98838069
2019-02-21 10:58:14,858 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /Users/monkeydlyffy/hadoop-2.8.1/data/current, StorageType: DISK
2019-02-21 10:58:14,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-02-21 10:58:14,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2019-02-21 10:58:14,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-2058785796-10.151.1.170-1550698384810
2019-02-21 10:58:14,868 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current...
2019-02-21 10:58:14,885 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-2058785796-10.151.1.170-1550698384810 on /Users/monkeydlyffy/hadoop-2.8.1/data/current: 17ms
2019-02-21 10:58:14,885 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-2058785796-10.151.1.170-1550698384810: 19ms
2019-02-21 10:58:14,886 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current...
2019-02-21 10:58:14,887 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/replicas doesn't exist 
2019-02-21 10:58:14,890 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current: 3ms
2019-02-21 10:58:14,890 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2019-02-21 10:58:14,928 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/Users/monkeydlyffy/hadoop-2.8.1/data, DS-0d9bb1b0-7e9e-4c26-bcc7-ac7f98838069): no suitable block pools found to scan.  Waiting 1744553528 ms.
2019-02-21 10:58:14,936 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/21/19, 2:45 PM with interval of 21600000ms
2019-02-21 10:58:14,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-2058785796-10.151.1.170-1550698384810 (Datanode Uuid 38fba316-5bd4-419c-b295-da4bfcdd1ab5) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-02-21 10:58:14,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-2058785796-10.151.1.170-1550698384810 (Datanode Uuid 38fba316-5bd4-419c-b295-da4bfcdd1ab5) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-02-21 10:58:14,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-02-21 10:58:15,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xcd02dc181f299a70,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 3 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-02-21 10:58:15,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-2058785796-10.151.1.170-1550698384810
2019-02-21 11:03:46,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741831_1007 src: /127.0.0.1:49825 dest: /127.0.0.1:50010
2019-02-21 11:03:46,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49825, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_397474886_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741831_1007, duration: 11455895
2019-02-21 11:03:46,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2019-02-21 11:03:47,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741832_1008 src: /127.0.0.1:49826 dest: /127.0.0.1:50010
2019-02-21 11:03:47,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49826, dest: /127.0.0.1:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_397474886_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741832_1008, duration: 2083225
2019-02-21 11:03:47,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2019-02-21 11:03:47,494 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741833_1009 src: /127.0.0.1:49827 dest: /127.0.0.1:50010
2019-02-21 11:03:47,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49827, dest: /127.0.0.1:50010, bytes: 27, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_397474886_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741833_1009, duration: 2234063
2019-02-21 11:03:47,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2019-02-21 11:03:47,622 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741834_1010 src: /127.0.0.1:49828 dest: /127.0.0.1:50010
2019-02-21 11:03:47,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49828, dest: /127.0.0.1:50010, bytes: 113633, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_397474886_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741834_1010, duration: 2124584
2019-02-21 11:03:47,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2019-02-21 11:03:51,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741835_1011 src: /127.0.0.1:49834 dest: /127.0.0.1:50010
2019-02-21 11:03:51,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49834, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_397474886_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741835_1011, duration: 4511265
2019-02-21 11:03:51,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2019-02-21 11:03:54,246 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2019-02-21 11:03:54,247 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741835_1011 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741835
2019-02-21 11:04:39,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741836_1012 src: /127.0.0.1:49838 dest: /127.0.0.1:50010
2019-02-21 11:04:39,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49838, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1099393901_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741836_1012, duration: 8899429
2019-02-21 11:04:39,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2019-02-21 11:04:39,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741837_1013 src: /127.0.0.1:49839 dest: /127.0.0.1:50010
2019-02-21 11:04:39,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49839, dest: /127.0.0.1:50010, bytes: 125, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1099393901_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741837_1013, duration: 1750767
2019-02-21 11:04:39,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2019-02-21 11:04:39,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741838_1014 src: /127.0.0.1:49840 dest: /127.0.0.1:50010
2019-02-21 11:04:40,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49840, dest: /127.0.0.1:50010, bytes: 27, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1099393901_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741838_1014, duration: 1845548
2019-02-21 11:04:40,003 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2019-02-21 11:04:40,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741839_1015 src: /127.0.0.1:49841 dest: /127.0.0.1:50010
2019-02-21 11:04:40,126 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49841, dest: /127.0.0.1:50010, bytes: 113633, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1099393901_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741839_1015, duration: 2357118
2019-02-21 11:04:40,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2019-02-21 11:04:43,437 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741840_1016 src: /127.0.0.1:49847 dest: /127.0.0.1:50010
2019-02-21 11:04:43,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49847, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1099393901_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741840_1016, duration: 2537447
2019-02-21 11:04:43,441 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2019-02-21 11:04:48,286 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2019-02-21 11:04:48,287 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741840_1016 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741840
2019-02-21 11:12:51,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741841_1017 src: /127.0.0.1:49904 dest: /127.0.0.1:50010
2019-02-21 11:12:51,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49904, dest: /127.0.0.1:50010, bytes: 2286, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1228495240_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741841_1017, duration: 6724771
2019-02-21 11:12:51,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2019-02-21 11:13:25,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741842_1018 src: /127.0.0.1:49914 dest: /127.0.0.1:50010
2019-02-21 11:13:25,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49914, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1921876695_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741842_1018, duration: 9620241
2019-02-21 11:13:25,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2019-02-21 11:13:25,665 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741843_1019 src: /127.0.0.1:49915 dest: /127.0.0.1:50010
2019-02-21 11:13:25,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49915, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1921876695_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741843_1019, duration: 2097172
2019-02-21 11:13:25,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2019-02-21 11:13:25,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741844_1020 src: /127.0.0.1:49916 dest: /127.0.0.1:50010
2019-02-21 11:13:25,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49916, dest: /127.0.0.1:50010, bytes: 27, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1921876695_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741844_1020, duration: 1657035
2019-02-21 11:13:25,703 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2019-02-21 11:13:25,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741845_1021 src: /127.0.0.1:49917 dest: /127.0.0.1:50010
2019-02-21 11:13:25,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49917, dest: /127.0.0.1:50010, bytes: 113620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1921876695_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741845_1021, duration: 2986795
2019-02-21 11:13:25,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2019-02-21 11:13:29,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741846_1022 src: /127.0.0.1:49923 dest: /127.0.0.1:50010
2019-02-21 11:13:29,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49923, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1921876695_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741846_1022, duration: 2672227
2019-02-21 11:13:29,143 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2019-02-21 11:13:33,756 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741846_1022 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741846 for deletion
2019-02-21 11:13:33,757 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741846_1022 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741846
2019-02-21 11:18:59,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741847_1023 src: /127.0.0.1:49952 dest: /127.0.0.1:50010
2019-02-21 11:18:59,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49952, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_295376044_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741847_1023, duration: 8400231
2019-02-21 11:18:59,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2019-02-21 11:19:00,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741848_1024 src: /127.0.0.1:49953 dest: /127.0.0.1:50010
2019-02-21 11:19:00,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49953, dest: /127.0.0.1:50010, bytes: 120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_295376044_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741848_1024, duration: 1831125
2019-02-21 11:19:00,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2019-02-21 11:19:00,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741849_1025 src: /127.0.0.1:49954 dest: /127.0.0.1:50010
2019-02-21 11:19:00,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49954, dest: /127.0.0.1:50010, bytes: 27, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_295376044_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741849_1025, duration: 1811631
2019-02-21 11:19:00,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2019-02-21 11:19:00,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741850_1026 src: /127.0.0.1:49955 dest: /127.0.0.1:50010
2019-02-21 11:19:00,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49955, dest: /127.0.0.1:50010, bytes: 113620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_295376044_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741850_1026, duration: 2732178
2019-02-21 11:19:00,203 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2019-02-21 11:19:02,484 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741851_1027 src: /127.0.0.1:49961 dest: /127.0.0.1:50010
2019-02-21 11:19:02,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49961, dest: /127.0.0.1:50010, bytes: 301938, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_295376044_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741851_1027, duration: 2733396
2019-02-21 11:19:02,488 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2019-02-21 11:19:07,044 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2019-02-21 11:19:07,045 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741851_1027 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741851
2019-02-21 11:38:03,996 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1091ms
No GCs detected
2019-02-21 12:43:55,464 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1191ms
No GCs detected
2019-02-21 12:51:50,361 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1132ms
No GCs detected
2019-02-21 12:53:01,331 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1188ms
No GCs detected
2019-02-21 13:07:31,724 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1020ms
No GCs detected
2019-02-21 13:08:10,552 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1281ms
No GCs detected
2019-02-21 13:31:25,294 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1131ms
No GCs detected
2019-02-21 14:06:00,996 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "Monkeys-MacBook-Pro.local/10.151.3.206"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1786)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1155)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1052)
2019-02-21 14:06:05,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-21 14:06:06,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-21 14:06:07,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-21 14:06:08,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-21 14:06:08,834 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-02-21 14:06:08,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at Monkeys-MBP/192.168.1.134
************************************************************/
2019-02-22 19:51:16,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = monkeydlyffy
STARTUP_MSG:   host = Monkeys-MBP/192.168.1.134
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/monkeydlyffy/hadoop-2.8.1/etc/hadoop:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 11.0.2
************************************************************/
2019-02-22 19:51:16,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 19:51:16,859 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-02-22 19:51:17,112 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 19:51:17,184 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 19:51:17,184 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-02-22 19:51:17,189 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-02-22 19:51:17,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is monkeys-mbp
2019-02-22 19:51:17,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-02-22 19:51:17,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-02-22 19:51:17,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2019-02-22 19:51:17,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-02-22 19:51:17,274 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-22 19:51:17,279 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 19:51:17,284 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-02-22 19:51:17,288 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 19:51:17,290 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-02-22 19:51:17,290 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 19:51:17,290 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 19:51:17,300 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 52250
2019-02-22 19:51:17,300 INFO org.mortbay.log: jetty-6.1.26
2019-02-22 19:51:17,353 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52250
2019-02-22 19:51:17,430 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-02-22 19:51:17,495 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-02-22 19:51:17,499 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 19:51:17,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = monkeydlyffy
2019-02-22 19:51:17,527 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-02-22 19:51:17,552 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 19:51:17,560 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-02-22 19:51:17,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-02-22 19:51:17,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-02-22 19:51:17,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-02-22 19:51:17,625 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-02-22 19:51:17,632 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 19:51:17,632 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-02-22 19:51:17,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-02-22 19:51:17,785 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-02-22 19:51:17,791 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /Users/monkeydlyffy/hadoop-2.8.1/data/in_use.lock acquired by nodename 21851@Monkeys-MBP
2019-02-22 19:51:17,832 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-2058785796-10.151.1.170-1550698384810
2019-02-22 19:51:17,832 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810
2019-02-22 19:51:17,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2023373140;bpid=BP-2058785796-10.151.1.170-1550698384810;lv=-57;nsInfo=lv=-63;cid=CID-f007f2a9-35ba-4354-9294-82cd50046184;nsid=2023373140;c=1550698384810;bpid=BP-2058785796-10.151.1.170-1550698384810;dnuuid=38fba316-5bd4-419c-b295-da4bfcdd1ab5
2019-02-22 19:51:17,861 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-0d9bb1b0-7e9e-4c26-bcc7-ac7f98838069
2019-02-22 19:51:17,861 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /Users/monkeydlyffy/hadoop-2.8.1/data/current, StorageType: DISK
2019-02-22 19:51:17,865 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-02-22 19:51:17,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2019-02-22 19:51:17,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-2058785796-10.151.1.170-1550698384810
2019-02-22 19:51:17,869 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current...
2019-02-22 19:51:17,876 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current: 282624
2019-02-22 19:51:17,878 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-2058785796-10.151.1.170-1550698384810 on /Users/monkeydlyffy/hadoop-2.8.1/data/current: 8ms
2019-02-22 19:51:17,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-2058785796-10.151.1.170-1550698384810: 10ms
2019-02-22 19:51:17,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current...
2019-02-22 19:51:17,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/replicas doesn't exist 
2019-02-22 19:51:17,883 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current: 3ms
2019-02-22 19:51:17,883 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 3ms
2019-02-22 19:51:17,921 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/Users/monkeydlyffy/hadoop-2.8.1/data, DS-0d9bb1b0-7e9e-4c26-bcc7-ac7f98838069): no suitable block pools found to scan.  Waiting 1626170535 ms.
2019-02-22 19:51:17,927 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/22/19, 10:39 PM with interval of 21600000ms
2019-02-22 19:51:17,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-2058785796-10.151.1.170-1550698384810 (Datanode Uuid 38fba316-5bd4-419c-b295-da4bfcdd1ab5) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-02-22 19:51:17,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-2058785796-10.151.1.170-1550698384810 (Datanode Uuid 38fba316-5bd4-419c-b295-da4bfcdd1ab5) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-02-22 19:51:17,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-02-22 19:51:18,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x21f4cf43c59844b9,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 3 msec to generate and 33 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-02-22 19:51:18,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-2058785796-10.151.1.170-1550698384810
2019-02-22 19:55:51,248 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741963_1139 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741963 for deletion
2019-02-22 19:55:51,249 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741963_1139 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741963
2019-02-22 19:57:29,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741968_1144 src: /127.0.0.1:52291 dest: /127.0.0.1:50010
2019-02-22 19:57:29,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52291, dest: /127.0.0.1:50010, bytes: 2139058, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1797035655_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741968_1144, duration: 14367664
2019-02-22 19:57:29,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741968_1144, type=LAST_IN_PIPELINE terminating
2019-02-22 19:59:50,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741969_1145 src: /127.0.0.1:52305 dest: /127.0.0.1:50010
2019-02-22 19:59:50,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52305, dest: /127.0.0.1:50010, bytes: 4924, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1690508873_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741969_1145, duration: 7501678
2019-02-22 19:59:50,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741969_1145, type=LAST_IN_PIPELINE terminating
2019-02-22 19:59:50,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741970_1146 src: /127.0.0.1:52306 dest: /127.0.0.1:50010
2019-02-22 19:59:50,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52306, dest: /127.0.0.1:50010, bytes: 117, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1690508873_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741970_1146, duration: 2543081
2019-02-22 19:59:50,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741970_1146, type=LAST_IN_PIPELINE terminating
2019-02-22 19:59:50,322 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741971_1147 src: /127.0.0.1:52307 dest: /127.0.0.1:50010
2019-02-22 19:59:50,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52307, dest: /127.0.0.1:50010, bytes: 28, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1690508873_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741971_1147, duration: 2112646
2019-02-22 19:59:50,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741971_1147, type=LAST_IN_PIPELINE terminating
2019-02-22 19:59:50,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741972_1148 src: /127.0.0.1:52308 dest: /127.0.0.1:50010
2019-02-22 19:59:50,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52308, dest: /127.0.0.1:50010, bytes: 113222, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1690508873_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741972_1148, duration: 2784716
2019-02-22 19:59:50,463 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741972_1148, type=LAST_IN_PIPELINE terminating
2019-02-22 19:59:55,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741973_1149 src: /127.0.0.1:52319 dest: /127.0.0.1:50010
2019-02-22 19:59:55,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52319, dest: /127.0.0.1:50010, bytes: 134453, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094523377_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741973_1149, duration: 6311482
2019-02-22 19:59:55,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741973_1149, type=LAST_IN_PIPELINE terminating
2019-02-22 19:59:59,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741974_1150 src: /127.0.0.1:52325 dest: /127.0.0.1:50010
2019-02-22 20:00:04,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741975_1151 src: /127.0.0.1:52330 dest: /127.0.0.1:50010
2019-02-22 20:00:04,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52330, dest: /127.0.0.1:50010, bytes: 1154706, op: HDFS_WRITE, cliID: DFSClient_attempt_1550886705704_0001_r_000000_0_467386734_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741975_1151, duration: 10561996
2019-02-22 20:00:04,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741975_1151, type=LAST_IN_PIPELINE terminating
2019-02-22 20:00:04,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52325, dest: /127.0.0.1:50010, bytes: 33489, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094523377_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741974_1150, duration: 4836900953
2019-02-22 20:00:04,319 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741974_1150, type=LAST_IN_PIPELINE terminating
2019-02-22 20:00:04,749 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741976_1152 src: /127.0.0.1:52331 dest: /127.0.0.1:50010
2019-02-22 20:00:04,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52331, dest: /127.0.0.1:50010, bytes: 355, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094523377_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741976_1152, duration: 2401280
2019-02-22 20:00:04,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741976_1152, type=LAST_IN_PIPELINE terminating
2019-02-22 20:00:04,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741977_1153 src: /127.0.0.1:52333 dest: /127.0.0.1:50010
2019-02-22 20:00:04,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52333, dest: /127.0.0.1:50010, bytes: 33489, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094523377_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741977_1153, duration: 2101676
2019-02-22 20:00:04,799 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741977_1153, type=LAST_IN_PIPELINE terminating
2019-02-22 20:00:05,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741978_1154 src: /127.0.0.1:52334 dest: /127.0.0.1:50010
2019-02-22 20:00:05,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52334, dest: /127.0.0.1:50010, bytes: 134453, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094523377_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741978_1154, duration: 2456210
2019-02-22 20:00:05,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741978_1154, type=LAST_IN_PIPELINE terminating
2019-02-22 20:00:06,492 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741969_1145 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741969 for deletion
2019-02-22 20:00:06,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741970_1146 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741970 for deletion
2019-02-22 20:00:06,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741971_1147 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741971 for deletion
2019-02-22 20:00:06,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741972_1148 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741972 for deletion
2019-02-22 20:00:06,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741973_1149 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741973 for deletion
2019-02-22 20:00:06,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741974_1150 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741974 for deletion
2019-02-22 20:00:06,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741969_1145 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741969
2019-02-22 20:00:06,494 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741970_1146 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741970
2019-02-22 20:00:06,494 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741971_1147 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741971
2019-02-22 20:00:06,494 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741972_1148 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741972
2019-02-22 20:00:06,495 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741973_1149 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741973
2019-02-22 20:00:06,495 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2058785796-10.151.1.170-1550698384810 blk_1073741974_1150 file /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/finalized/subdir0/subdir0/blk_1073741974
2019-02-22 21:29:29,395 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "Monkeys-MBP/192.168.1.134"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1786)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1155)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1052)
2019-02-22 21:29:33,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:34,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:35,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:36,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:37,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:38,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:39,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:40,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:41,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:42,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:42,347 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-02-22 21:29:42,348 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From Monkeys-MBP/192.168.1.134 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 9 more
2019-02-22 21:29:44,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:45,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:46,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:47,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:48,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:49,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:50,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:51,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:52,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:53,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:29:53,391 WARN org.apache.hadoop.ipc.Client: Failed to connect to server: localhost/127.0.0.1:9000: retries get failed due to exceeded maximum allowed retries number: 10
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-02-22 21:29:53,398 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.net.ConnectException: Call From Monkeys-MBP/192.168.1.134 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:801)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:732)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1485)
	at org.apache.hadoop.ipc.Client.call(Client.java:1427)
	at org.apache.hadoop.ipc.Client.call(Client.java:1337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:456)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:577)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:771)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:495)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:681)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:777)
	at org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:409)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1542)
	at org.apache.hadoop.ipc.Client.call(Client.java:1373)
	... 9 more
2019-02-22 21:29:55,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-02-22 21:30:32,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   user = monkeydlyffy
STARTUP_MSG:   host = Monkeys-MBP/192.168.1.134
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.8.1
STARTUP_MSG:   classpath = /Users/monkeydlyffy/hadoop-2.8.1/etc/hadoop:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-digester-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpclient-4.5.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsp-api-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/hadoop-auth-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/httpcore-4.4.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-net-3.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/gson-2.2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/json-smart-1.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsch-0.1.51.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-common-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/common/hadoop-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/htrace-core4-4.0.1-incubating.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-native-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/hdfs/hadoop-hdfs-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/activation-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-math-2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/fst-2.24.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/objenesis-2.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jettison-1.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-api-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-registry-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-client-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.8.1.jar:/Users/monkeydlyffy/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 20fe5304904fc2f5a18053c389e43cd26f7a70fe; compiled by 'vinodkv' on 2017-06-02T06:14Z
STARTUP_MSG:   java = 1.8.0_201
************************************************************/
2019-02-22 21:30:32,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-02-22 21:30:32,769 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-02-22 21:30:33,012 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-02-22 21:30:33,055 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-02-22 21:30:33,055 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-02-22 21:30:33,059 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-02-22 21:30:33,060 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is monkeys-mbp
2019-02-22 21:30:33,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-02-22 21:30:33,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-02-22 21:30:33,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 10485760 bytes/s
2019-02-22 21:30:33,092 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-02-22 21:30:33,142 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-02-22 21:30:33,146 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-02-22 21:30:33,150 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-02-22 21:30:33,153 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-02-22 21:30:33,154 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-02-22 21:30:33,154 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-02-22 21:30:33,154 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-02-22 21:30:33,164 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 53199
2019-02-22 21:30:33,164 INFO org.mortbay.log: jetty-6.1.26
2019-02-22 21:30:33,258 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:53199
2019-02-22 21:30:33,407 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-02-22 21:30:33,410 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-02-22 21:30:33,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = monkeydlyffy
2019-02-22 21:30:33,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-02-22 21:30:33,560 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-02-22 21:30:33,569 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-02-22 21:30:33,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-02-22 21:30:33,610 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-02-22 21:30:33,616 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-02-22 21:30:33,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-02-22 21:30:33,628 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-02-22 21:30:33,628 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-02-22 21:30:33,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-02-22 21:30:33,782 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-02-22 21:30:33,788 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /Users/monkeydlyffy/hadoop-2.8.1/data/in_use.lock acquired by nodename 24152@Monkeys-MBP
2019-02-22 21:30:33,827 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-2058785796-10.151.1.170-1550698384810
2019-02-22 21:30:33,827 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810
2019-02-22 21:30:33,829 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2023373140;bpid=BP-2058785796-10.151.1.170-1550698384810;lv=-57;nsInfo=lv=-63;cid=CID-f007f2a9-35ba-4354-9294-82cd50046184;nsid=2023373140;c=1550698384810;bpid=BP-2058785796-10.151.1.170-1550698384810;dnuuid=38fba316-5bd4-419c-b295-da4bfcdd1ab5
2019-02-22 21:30:33,860 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-0d9bb1b0-7e9e-4c26-bcc7-ac7f98838069
2019-02-22 21:30:33,860 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /Users/monkeydlyffy/hadoop-2.8.1/data/current, StorageType: DISK
2019-02-22 21:30:33,863 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-02-22 21:30:33,866 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
2019-02-22 21:30:33,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-2058785796-10.151.1.170-1550698384810
2019-02-22 21:30:33,867 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current...
2019-02-22 21:30:33,882 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-2058785796-10.151.1.170-1550698384810 on /Users/monkeydlyffy/hadoop-2.8.1/data/current: 14ms
2019-02-22 21:30:33,882 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-2058785796-10.151.1.170-1550698384810: 15ms
2019-02-22 21:30:33,883 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current...
2019-02-22 21:30:33,883 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /Users/monkeydlyffy/hadoop-2.8.1/data/current/BP-2058785796-10.151.1.170-1550698384810/current/replicas doesn't exist 
2019-02-22 21:30:33,887 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2058785796-10.151.1.170-1550698384810 on volume /Users/monkeydlyffy/hadoop-2.8.1/data/current: 4ms
2019-02-22 21:30:33,887 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 5ms
2019-02-22 21:30:33,922 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/Users/monkeydlyffy/hadoop-2.8.1/data, DS-0d9bb1b0-7e9e-4c26-bcc7-ac7f98838069): no suitable block pools found to scan.  Waiting 1620214535 ms.
2019-02-22 21:30:33,932 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 2/23/19 1:10 AM with interval of 21600000ms
2019-02-22 21:30:33,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-2058785796-10.151.1.170-1550698384810 (Datanode Uuid 38fba316-5bd4-419c-b295-da4bfcdd1ab5) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-02-22 21:30:33,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-2058785796-10.151.1.170-1550698384810 (Datanode Uuid 38fba316-5bd4-419c-b295-da4bfcdd1ab5) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-02-22 21:30:33,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-02-22 21:30:34,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x670fb97cb229482a,  containing 1 storage report(s), of which we sent 1. The reports had 9 total blocks and used 1 RPC(s). This took 3 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-02-22 21:30:34,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-2058785796-10.151.1.170-1550698384810
2019-02-22 21:41:12,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741979_1155 src: /127.0.0.1:53320 dest: /127.0.0.1:50010
2019-02-22 21:41:12,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2058785796-10.151.1.170-1550698384810:blk_1073741980_1156 src: /127.0.0.1:53319 dest: /127.0.0.1:50010
2019-02-22 21:41:12,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53319, dest: /127.0.0.1:50010, bytes: 607546, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36168203_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741980_1156, duration: 23165863
2019-02-22 21:41:12,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:53320, dest: /127.0.0.1:50010, bytes: 590360, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_36168203_1, offset: 0, srvID: 38fba316-5bd4-419c-b295-da4bfcdd1ab5, blockid: BP-2058785796-10.151.1.170-1550698384810:blk_1073741979_1155, duration: 23228848
2019-02-22 21:41:12,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741979_1155, type=LAST_IN_PIPELINE terminating
2019-02-22 21:41:12,340 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2058785796-10.151.1.170-1550698384810:blk_1073741980_1156, type=LAST_IN_PIPELINE terminating
